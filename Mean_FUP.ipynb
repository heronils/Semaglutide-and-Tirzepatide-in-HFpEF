{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36ab945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import lifelines\n",
    "import pandas\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines import CoxPHFitter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c85c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "merged_data = pd.read_csv(\"path/to/cohort_file.csv\")\n",
    "merged_data_key = pd.read_csv(\"path/to/cohort_file.csv\")\n",
    "\n",
    "# Create and apply a column renaming mapping for merged_data\n",
    "cohort_mapping = dict(zip(merged_data_key[\"Column Name\"], merged_data_key[\"Description\"]))\n",
    "cohort_mapping.pop('PID', None)  # Ensure 'PID' remains unchanged\n",
    "trimmed_cohort_mapping = {col: desc.split(\" - \")[-1] for col, desc in cohort_mapping.items()}\n",
    "merged_data.rename(columns=trimmed_cohort_mapping, inplace=True)\n",
    "\n",
    "# Calculate overlap weights\n",
    "merged_data['overlap_weight'] = merged_data['Propensity Score']\n",
    "merged_data.loc[merged_data['Exposure Group'] == 'E', 'overlap_weight'] = 1 - merged_data['Propensity Score']\n",
    "\n",
    "# Inspect the final dataset\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52ab163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Effective Sample Size (ESS_optum)\n",
    "sum_weights = merged_data[\"overlap_weight\"].sum()\n",
    "sum_weights_squared = (merged_data[\"overlap_weight\"] ** 2).sum()\n",
    "ESS_optum = (sum_weights ** 2) / sum_weights_squared\n",
    "\n",
    "print(f\"Computed Effective Sample Size (ESS_optum): {ESS_optum:.2f}\")\n",
    "\n",
    "# Normalize weights to ensure sum equals ESS_optum\n",
    "scaling_factor = ESS_optum / sum_weights\n",
    "merged_data[\"overlap_weight\"] = merged_data[\"overlap_weight\"] * scaling_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1934dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Individual databases\n",
    "datasets = {\n",
    "    'Optum': merged_data,\n",
    "}\n",
    "\n",
    "# Overall weighted mean and SD per database\n",
    "for name, data in datasets.items():\n",
    "    mean = np.average(data['Follow Up Time'], weights=data['overlap_weight'])\n",
    "    variance = np.average((data['Follow Up Time'] - mean) ** 2, weights=data['overlap_weight'])\n",
    "    sd = np.sqrt(variance)\n",
    "    \n",
    "    print(f\"{name} Weighted Mean Follow-up Time: {mean:.1f}\")\n",
    "    print(f\"{name} Weighted SD of Follow-up Time: {sd:.1f}\\n\")\n",
    "    \n",
    "    # Stratified by Exposure Group\n",
    "    print(f\"{name} Stratified Weighted Follow-up Time by Exposure Group:\")\n",
    "    for group, group_df in data.groupby(\"Exposure Group\"):\n",
    "        group_mean = np.average(group_df[\"Follow Up Time\"], weights=group_df[\"overlap_weight\"])\n",
    "        group_variance = np.average((group_df[\"Follow Up Time\"] - group_mean) ** 2, weights=group_df[\"overlap_weight\"])\n",
    "        group_sd = np.sqrt(group_variance)\n",
    "\n",
    "        print(f\"  Group {group}: Mean = {group_mean:.1f} days, SD = {group_sd:.1f} days\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
